import logging
import os
import asyncio
import httpx
import trafilatura

logger = logging.getLogger(__name__)


def _is_jina_configured() -> bool:
    """æ£€æŸ¥æ˜¯å¦é…ç½®äº† Jina API Key."""
    api_key = os.getenv("JINA_API_KEY")
    return bool(api_key and api_key.strip())


async def _get_content_with_jina(
    url: str, client: httpx.AsyncClient
) -> tuple[str, str | None]:
    """ä½¿ç”¨ Jina Reader API è·å–å†…å®¹."""
    api_key = os.getenv("JINA_API_KEY")
    if not api_key:
        return url, None

    try:
        # Jina Reader API: https://r.jina.ai/{url}
        jina_url = f"https://r.jina.ai/{url}"
        headers = {
            "Authorization": f"Bearer {api_key}",
            "Accept": "text/markdown",
        }

        resp = await client.get(
            jina_url, headers=headers, timeout=30.0, follow_redirects=True
        )
        resp.raise_for_status()

        content = resp.text.strip()
        if not content:
            logger.warning("[CRAWLER] âš ï¸ Jina è¿”å›ç©ºå†…å®¹: %s", url)
            return url, None

        logger.info("[CRAWLER] âœ… ä½¿ç”¨ Jina æˆåŠŸè·å–å†…å®¹: %s", url)
        return url, content

    except httpx.TimeoutException:
        logger.warning("[CRAWLER] â±ï¸ Jina è¯·æ±‚è¶…æ—¶: %s", url)
        return url, None

    except httpx.HTTPStatusError as exc:
        logger.warning(
            "[CRAWLER] âŒ Jina HTTPé”™è¯¯ %d: %s", exc.response.status_code, url
        )
        return url, None

    except httpx.RequestError as exc:
        logger.warning(
            "[CRAWLER] ğŸ”Œ Jina ç½‘ç»œè¯·æ±‚å¤±è´¥ (%s): %s", type(exc).__name__, url
        )
        return url, None

    except Exception as exc:
        logger.error(
            "[CRAWLER] ğŸ’¥ Jina æœªçŸ¥é”™è¯¯ (%s: %s): %s", type(exc).__name__, exc, url
        )
        return url, None


async def get_content(url: str, client: httpx.AsyncClient) -> tuple[str, str | None]:
    """ä½¿ç”¨ httpx + trafilatura å®ç°çš„è¶…è½»é‡æŠ“å–."""
    try:
        # 1. å¼‚æ­¥ä¸‹è½½ç½‘é¡µå†…å®¹
        resp = await client.get(url, timeout=10.0, follow_redirects=True)
        resp.raise_for_status()

        # 2. trafilatura æå–æ­£æ–‡å¹¶ç›´æ¥è½¬ä¸º Markdown
        # include_links=True å¯ä»¥ä¿ç•™é“¾æ¥ï¼Œæ–¹ä¾¿ LLM æº¯æº
        content = trafilatura.extract(
            resp.text, include_links=True, output_format="markdown"
        )

        if content is None:
            logger.warning("[CRAWLER] âš ï¸ å†…å®¹æå–å¤±è´¥ (trafilaturaè¿”å›ç©º): %s", url)

            # Fallback to Jina if configured
            if _is_jina_configured():
                logger.info("[CRAWLER] ğŸ”„ å°è¯•ä½¿ç”¨ Jina ä½œä¸º fallback: %s", url)
                return await _get_content_with_jina(url, client)

            return url, None

        return url, content

    except httpx.TimeoutException:
        error_msg = f"[CRAWLER] â±ï¸ è¯·æ±‚è¶…æ—¶: {url}"
        logger.warning("[CRAWLER] â±ï¸ è¯·æ±‚è¶…æ—¶: %s", url)
        print(error_msg)

        # Fallback to Jina if configured
        if _is_jina_configured():
            logger.info("[CRAWLER] ğŸ”„ å°è¯•ä½¿ç”¨ Jina ä½œä¸º fallback: %s", url)
            return await _get_content_with_jina(url, client)

        return url, None

    except httpx.HTTPStatusError as exc:
        error_msg = f"[CRAWLER] âŒ HTTPé”™è¯¯ {exc.response.status_code}: {url}"
        logger.warning("[CRAWLER] âŒ HTTPé”™è¯¯ %d: %s", exc.response.status_code, url)
        print(error_msg)

        # Fallback to Jina if configured (only for client errors, not server errors)
        if exc.response.status_code < 500 and _is_jina_configured():
            logger.info("[CRAWLER] ğŸ”„ å°è¯•ä½¿ç”¨ Jina ä½œä¸º fallback: %s", url)
            return await _get_content_with_jina(url, client)

        return url, None

    except httpx.RequestError as exc:
        error_msg = f"[CRAWLER] ğŸ”Œ ç½‘ç»œè¯·æ±‚å¤±è´¥ ({type(exc).__name__}): {url}"
        logger.warning(
            "[CRAWLER] ğŸ”Œ ç½‘ç»œè¯·æ±‚å¤±è´¥ (%s): %s", type(exc).__name__, url
        )
        print(error_msg)

        # Fallback to Jina if configured
        if _is_jina_configured():
            logger.info("[CRAWLER] ğŸ”„ å°è¯•ä½¿ç”¨ Jina ä½œä¸º fallback: %s", url)
            return await _get_content_with_jina(url, client)

        return url, None

    except Exception as exc:
        error_msg = f"[CRAWLER] ğŸ’¥ æœªçŸ¥é”™è¯¯ ({type(exc).__name__}: {exc}): {url}"
        logger.error(
            "[CRAWLER] ğŸ’¥ æœªçŸ¥é”™è¯¯ (%s: %s): %s", type(exc).__name__, exc, url
        )
        print(error_msg)

        # Fallback to Jina if configured
        if _is_jina_configured():
            logger.info("[CRAWLER] ğŸ”„ å°è¯•ä½¿ç”¨ Jina ä½œä¸º fallback: %s", url)
            return await _get_content_with_jina(url, client)

        return url, None


async def fetch_all_contents(urls: list[str]) -> dict[str, str]:
    """ä½¿ç”¨å¼‚æ­¥ IO æ‰¹é‡æŠ“å–."""
    if not urls:
        return {}

    # ä½¿ç”¨å¼‚æ­¥ Client å…±äº«è¿æ¥æ± 
    async with httpx.AsyncClient(limits=httpx.Limits(max_connections=20)) as client:
        tasks = [get_content(url, client) for url in urls]
        results_list = await asyncio.gather(*tasks)
        return {url: content for url, content in results_list if content}
